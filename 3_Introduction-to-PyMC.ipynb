{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyMC\n",
    "\n",
    "While Markov chain Monte Carlo is a powerful method for fitting Bayesian models, they can be difficult to apply generally, as most commercial statistical analysis packages do not implement it. This has been an impediment to the growth of Bayesian methods. PyMC is a python module that implements Bayesian statistical models and fitting algorithms, including MCMC. Its flexibility and extensibility make it applicable to a large suite of problems. Along with core sampling functionality, PyMC includes methods for summarizing\n",
    "output, plotting, goodness-of-fit and convergence diagnostics.\n",
    "\n",
    "PyMC 2.3 provides functionalities to make Bayesian analysis as painless as possible. Here is a short list of some of its features:\n",
    "\n",
    "-   Fits Bayesian statistical models with Markov chain Monte Carlo and\n",
    "    other algorithms.\n",
    "-   Includes a large suite of well-documented statistical distributions.\n",
    "-   Uses NumPy for numerics wherever possible.\n",
    "-   Includes a module for modeling Gaussian processes.\n",
    "-   Sampling loops can be paused and tuned manually, or saved and\n",
    "    restarted later.\n",
    "-   Creates summaries including tables and plots.\n",
    "-   Traces can be saved to the disk as plain text, Python pickles,\n",
    "    SQLite or MySQL database, or hdf5 archives.\n",
    "-   Several convergence diagnostics are available.\n",
    "-   Extensible: easily incorporates custom step methods and unusual\n",
    "    probability distributions.\n",
    "-   MCMC loops can be embedded in larger programs, and results can be\n",
    "    analyzed with the full power of Python.\n",
    "    \n",
    "Before we dig into PyMC in detail, let's look at a simple hierachical linear model of a house's price as a function of age, to give you a flavor for what Bayesian models look like when implemented in PyMC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "age = np.array([13, 14, 14,12, 9, 15, 10, 14, 9, 14, 13, 12, 9, 10, 15, 11, 15, \n",
    "                11, 7, 13, 13, 10, 9, 6, 11, 15, 13, 10, 9, 9, 15, 14, 14, 10, 14, 11, 13, 14, 10])\n",
    "price = np.array([2950, 2300, 3900, 2800, 5000, 2999, 3950, 2995, 4500, 2800, 1990, \n",
    "                  3500, 5100, 3900, 2900, 4950, 2000, 3400, 8999, 4000, 2950, 3250, \n",
    "                  3950, 4600, 4500, 1600, 3900, 4200, 6500, 3500, 2999, 2600, 3250, \n",
    "                  2500, 2400, 3990, 4600, 450,4700])/1000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pymc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f20a0e3996ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpymc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCMC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Constant priors for parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pymc"
     ]
    }
   ],
   "source": [
    "from pymc import Normal, Gamma, deterministic, MCMC, Matplot\n",
    "\n",
    "# Constant priors for parameters\n",
    "a = Normal('a', 0, 0.0001)\n",
    "b = Normal('b', 0, 0.0001)\n",
    "\n",
    "# Precision of normal distribution of prices\n",
    "tau = Gamma('tau', alpha=0.1, beta=0.1)\n",
    "\n",
    "@deterministic\n",
    "def mu(x=age, a=a, b=b):\n",
    "    # Linear age-price model\n",
    "    return a + b*x\n",
    "\n",
    "# Sampling distribution of prices\n",
    "p = Normal('p', mu, tau, value=price, observed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will generate 10000 posterior samples, thinned by a factor\n",
    "of 2, with the first half discarded as burn-in. The sample is stored in\n",
    "a Python serialization (pickle) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = MCMC(locals(), db='pickle')\n",
    "M.sample(iter=20000, burn=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "Matplot.plot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Coal mining disasters\n",
    "\n",
    "Recall the earlier example of estimating a changepoint in the time series of UK coal mining disasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pymc.examples.disaster_model import disasters_array\n",
    "\n",
    "plt.figure(figsize=(12.5, 3.5))\n",
    "n_count_data = len(disasters_array)\n",
    "plt.bar(np.arange(1851, 1962), disasters_array, color=\"#348ABD\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Disasters\")\n",
    "plt.title(\"UK coal mining disasters, 1851-1962\")\n",
    "plt.xlim(1851, 1962);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent our conceptual model formally as a statistical model:\n",
    "\n",
    "$$\\begin{array}{ccc}  \n",
    "(y_t | \\tau, \\lambda_1, \\lambda_2) \\sim\\text{Poisson}\\left(r_t\\right), & r_t=\\left\\{\n",
    "\\begin{array}{lll}             \n",
    "\\lambda_1 &\\text{if}& t< \\tau\\\\ \n",
    "\\lambda_2 &\\text{if}& t\\ge \\tau             \n",
    "\\end{array}\\right.,&t\\in[t_l,t_h]\\\\         \n",
    "\\tau \\sim \\text{DiscreteUniform}(t_l, t_h)\\\\         \n",
    "\\lambda_1\\sim \\text{Exponential}(a)\\\\         \n",
    "\\lambda_2\\sim \\text{Exponential}(b)     \n",
    "\\end{array}$$\n",
    "\n",
    "Because we have defined $y$ by its dependence on $\\tau$, $\\lambda_1$ and $\\lambda_2$, the\n",
    "latter three are known as the *parents* of $y$ and $D$ is called their\n",
    "*child*. Similarly, the parents of $\\tau$ are $t_l$ and $t_h$, and $\\tau$ is\n",
    "the child of $t_l$ and $t_h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC Variables\n",
    "\n",
    "At the model-specification stage (before the data are observed), $y$,\n",
    "$\\tau$, $\\lambda_1$, and $\\lambda_2$ are all random variables. Recall from the discussion of subjective probability that the Bayesian interpretation of probability is ***epistemic***, meaning random variable $x$'s probability distribution $p(x)$ represents our knowledge and uncertainty about $x$'s value, rather than some random generative process. Candidate\n",
    "values of $x$ for which $p(x)$ is high are relatively more probable, given what we know. Random variables are represented in PyMC by the classes `Stochastic` and `Deterministic`.\n",
    "\n",
    "The only `Deterministic` in the model is $r$. If we knew the values of\n",
    "$r$'s parents, we could compute the value of $r$\n",
    "exactly. A `Deterministic` like $r$ is defined by a mathematical\n",
    "function that returns its value given values for its parents.\n",
    "`Deterministic` variables are sometimes called the ***systemic*** part of\n",
    "the model. The nomenclature is a bit confusing, because these objects\n",
    "usually represent random variables; since the parents of $r$ are random,\n",
    "$r$ is random also.\n",
    "\n",
    "On the other hand, even if the values of the parents of variables\n",
    "`switchpoint`, `disasters` (before observing the data), `early_mean`\n",
    "or `late_mean` were known, we would still be uncertain of their values.\n",
    "These variables are characterized by probability distributions that\n",
    "express how plausible their candidate values are, given values for their\n",
    "parents. The `Stochastic` class represents these variables.\n",
    "\n",
    "First, we represent the unknown switchpoint as a discrete uniform random variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc import DiscreteUniform, Exponential, Poisson, deterministic\n",
    "\n",
    "switchpoint = DiscreteUniform('switchpoint', lower=0, upper=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switchpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DiscreteUniform` is a subclass of `Stochastic` that represents\n",
    "uniformly-distributed discrete variables. Use of this distribution\n",
    "suggests that we have no preference *a priori* regarding the location of\n",
    "the switchpoint; all values are equally likely. \n",
    "\n",
    "Now we create the\n",
    "exponentially-distributed variables `early_mean` and `late_mean` for the\n",
    "early and late Poisson rates, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_mean = Exponential('early_mean', beta=1., value=3)\n",
    "late_mean = Exponential('late_mean', beta=1., value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the variable `rate`, which selects the early rate\n",
    "`early_mean` for times before `switchpoint` and the late rate\n",
    "`late_mean` for times after `switchpoint`. We create `rate` using the\n",
    "`deterministic` decorator, which converts the ordinary Python function\n",
    "`rate` into a `Deterministic` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@deterministic\n",
    "def rate(s=switchpoint, e=early_mean, l=late_mean):\n",
    "    # Create a vector of Poisson means\n",
    "    out = np.empty(len(disasters_array))\n",
    "    out[:s] = e\n",
    "    out[s:] = l\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to define the number of disasters `disasters`. This is\n",
    "a stochastic variable but unlike `switchpoint`, `early_mean` and\n",
    "`late_mean` we have observed its value. To express this, we set the\n",
    "argument `observed` to `True` (it is set to `False` by default). This\n",
    "tells PyMC that this object's value should not be changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = Poisson('disasters', mu=rate, value=disasters_array, \n",
    "                    observed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why are data and unknown variables represented by the same object?\n",
    "\n",
    "Since its represented by a `Stochastic` object, `disasters` is defined\n",
    "by its dependence on its parent `rate` even though its value is fixed.\n",
    "This isn't just a quirk of PyMC's syntax; Bayesian hierarchical notation\n",
    "itself makes no distinction between random variables and data. The\n",
    "reason is simple: to use Bayes' theorem to compute the posterior, we require the\n",
    "likelihood. Even though `disasters`'s value is known\n",
    "and fixed, we need to formally assign it a probability distribution as\n",
    "if it were a random variable. \n",
    "\n",
    "Remember, the likelihood and the probability function are essentially the same, except that the former is regarded as a *function of the parameters* and the latter as a *function of\n",
    "the data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parents and children\n",
    "\n",
    "We have above created a PyMC probability model, which is simply a linked\n",
    "collection of variables. To see the nature of the links, we can examine any node's `parents` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switchpoint.parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `parents` dictionary shows us the distributional parameters of\n",
    "`switchpoint`, which are constants. Now let's examine the parents of `disasters` and `rate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters.parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate.parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `rate` as a distributional parameter of `disasters`\n",
    "(*i.e.* `rate` is `disasters`'s parent). `disasters` internally\n",
    "labels `rate` as `mu`, meaning `rate` plays the role of the rate\n",
    "parameter in `disasters`'s Poisson distribution. Now examine `rate`'s\n",
    "`children` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `disasters` considers `rate` its parent, `rate` considers `disasters` its child. Unlike `parents`, `children` is a set (an unordered collection of objects); variables do not associate their children with any particular distributional role, so an index is not required. Try examining the `parents` and `children` attributes of the other parameters in the model.\n",
    "\n",
    "The following **directed acyclic graph** is a visualization of the parent-child relationships in the model. Unobserved stochastic variables `switchpoint`, `early_mean` and `late_mean` are open ellipses, observed stochastic variable `disasters` is a filled ellipse and deterministic variable `rate` is a triangle. Arrows point from parent to child and display the label that the child assigns to the parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc import graph, MCMC\n",
    "graph.dag(MCMC([switchpoint, rate, early_mean, late_mean, disasters]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot MCMC.dot -Tpng -o images/dag.png\n",
    "from IPython.core.display import Image\n",
    "Image('images/dag.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the examples above have shown, PyMC objects need to have a name assigned, such as `switchpoint`, `early_mean` or `late_mean`. These names are used for storage and post-processing:\n",
    "\n",
    "-   as keys in on-disk databases,\n",
    "-   as node labels in model graphs,\n",
    "-   as axis labels in plots of traces,\n",
    "-   as table labels in summary statistics.\n",
    "\n",
    "A model instantiated with variables having identical names raises an\n",
    "error to avoid name conflicts in the database storing the traces. In\n",
    "general however, PyMC uses references to the objects themselves, not\n",
    "their names, to identify variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables' values and log-probabilities\n",
    "\n",
    "All PyMC variables have an attribute called `value` that stores the\n",
    "current value of that variable. Try examining `disasters`'s value, and\n",
    "you'll see the dataset we provided for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the values of `early_mean`, `switchpoint` and `late_mean`,\n",
    "you'll see random initial values generated by PyMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switchpoint.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_mean.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_mean.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, since these are `Stochastic` elements, your values will be\n",
    "different than these. If you check `rate`'s value, you'll see an array\n",
    "whose first `switchpoint` elements are `early_mean`,\n",
    "and whose remaining elements are `late_mean`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute its value, `rate` calls the function we used to create it,\n",
    "passing in the values of its parents.\n",
    "\n",
    "`Stochastic` objects can evaluate their probability mass or density\n",
    "functions at their current values given the values of their parents. The\n",
    "logarithm of a stochastic object's probability mass or density can be\n",
    "accessed via the `logp` attribute. For vector-valued variables like\n",
    "`disasters`, the `logp` attribute returns the sum of the logarithms of\n",
    "the joint probability or density of all elements of the value. \n",
    "\n",
    "Try examining `switchpoint`'s and `disasters`'s log-probabilities and\n",
    "`early_mean` 's and `late_mean`'s log-densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switchpoint.logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_mean.value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters.logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_mean.logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_mean.logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Stochastic` objects need to call an internal function to compute their\n",
    "`logp` attributes, as `rate` needed to call an internal function to\n",
    "compute its value. Just as we created `rate` by decorating a function\n",
    "that computes its value, it's possible to create custom `Stochastic`\n",
    "objects by decorating functions that compute their log-probabilities or\n",
    "densities (see chapter :ref:\\`chap\\_modelbuilding\\`). Users are thus not\n",
    "limited to the set of of statistical distributions provided by PyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Variables as parents of other Variables\n",
    "\n",
    "Let's take a closer look at our definition of `rate`:\n",
    "\n",
    "    @deterministic(plot=False)\n",
    "    def rate(s=switchpoint, e=early_mean, l=late_mean):\n",
    "        ''' Concatenate Poisson means '''\n",
    "        out = empty(len(disasters_array))\n",
    "        out[:s] = e\n",
    "        out[s:] = l\n",
    "        return out\n",
    "\n",
    "The arguments `switchpoint`, `early_mean` and `late_mean` are\n",
    "`Stochastic` objects, not numbers. If that is so, why aren't errors\n",
    "raised when we attempt to slice array `out` using a `Stochastic` object?\n",
    "\n",
    "Whenever a variable is used as a parent for a child variable, PyMC\n",
    "replaces it with its `value` attribute when the child's value or\n",
    "log-probability is computed. When `rate`'s value is recomputed,\n",
    "`s.value` is passed to the function as argument `switchpoint`. To see\n",
    "the values of the parents of `rate` all together, look at\n",
    "`rate.parents.value`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model with MCMC\n",
    "\n",
    "PyMC provides several objects that fit probability models (linked collections of variables) like ours. The primary such object, `MCMC`, fits models with a Markov chain Monte Carlo algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc.examples import disaster_model\n",
    "M = MCMC(disaster_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case `M` will expose variables `switchpoint`, `early_mean`,\n",
    "`late_mean` and `disasters` as attributes; that is, `M.switchpoint` will\n",
    "be the same object as `disaster_model.switchpoint`.\n",
    "\n",
    "To run the sampler, call the MCMC object's `sample()` (or `isample()`,\n",
    "for interactive sampling outside of the IPython notebook) method with arguments for the number of iterations, burn-in length, and thinning interval (if desired):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.sample(iter=10000, burn=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the samples\n",
    "\n",
    "The output of the MCMC algorithm is a `trace`, the sequence of\n",
    "retained samples for each variable in the model. These traces can be\n",
    "accessed using the `trace(name, chain=-1)` method. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.trace('switchpoint')[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace slice `[start:stop:step]` works just like the NumPy array\n",
    "slice. By default, the returned trace array contains the samples from\n",
    "the last call to `sample`, that is, `chain=-1`, but the trace from\n",
    "previous sampling runs can be retrieved by specifying the correspondent\n",
    "chain index. To return the trace from all chains, simply use\n",
    "`chain=None`.\n",
    "\n",
    "A node's chain can be accessed directly using its `trace` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.early_mean.trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling output\n",
    "\n",
    "You can examine the marginal posterior of any variable by plotting a\n",
    "histogram of its trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(M.trace('late_mean')[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyMC has its own plotting functionality, via the optional `matplotlib`\n",
    "module as noted in the installation notes. The `Matplot` module includes\n",
    "a `plot` function that takes the model (or a single parameter) as an\n",
    "argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc.Matplot import plot\n",
    "plot(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper left-hand pane of each figure shows the temporal series of the\n",
    "samples from each parameter, while below is an autocorrelation plot of\n",
    "the samples. The right-hand pane shows a histogram of the trace. The\n",
    "trace is useful for evaluating and diagnosing the algorithm's\n",
    "performance, while the histogram is useful for\n",
    "visualizing the posterior.\n",
    "\n",
    "An alternative visualization of posterior quantities is to use the `summary_plot` function to create forest plots of stochastic or determinsitic nodes. This will display the posterior median, interquartile range, and posterior credible interval (defaults to 95%) in a layout that makes it easy to compare multiple nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matplot.summary_plot([M.early_mean, M.late_mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a non-graphical summary of the posterior, simply call the `summary` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.early_mean.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Missing Data\n",
    "\n",
    "As with most textbook examples, the models we have examined so far\n",
    "assume that the associated data are complete. That is, there are no\n",
    "missing values corresponding to any observations in the dataset.\n",
    "However, many real-world datasets have missing observations, usually due\n",
    "to some logistical problem during the data collection process. The\n",
    "easiest way of dealing with observations that contain missing values is\n",
    "simply to exclude them from the analysis; this is called a **complete case analysis**. However, this results in loss\n",
    "of information if an excluded observation contains valid values for\n",
    "other quantities, and can bias results. An alternative is to ***impute*** the\n",
    "missing values, based on information in the rest of the model.\n",
    "\n",
    "For example, consider a survey dataset for some wildlife species:\n",
    "\n",
    "    Count   Site   Observer   Temperature\n",
    "    ------- ------ ---------- -------------\n",
    "    15      1      1          15\n",
    "    10      1      2          NA\n",
    "    6       1      1          11\n",
    "\n",
    "Each row contains the number of individuals seen during the survey,\n",
    "along with three covariates: the site on which the survey was conducted,\n",
    "the observer that collected the data, and the temperature during the\n",
    "survey. If we are interested in modelling, say, population size as a\n",
    "function of the count and the associated covariates, it is difficult to\n",
    "accommodate the second observation because the temperature is missing\n",
    "(perhaps the thermometer was broken that day). Ignoring this observation\n",
    "will allow us to fit the model, but it wastes information that is\n",
    "contained in the other covariates.\n",
    "\n",
    "In a Bayesian modelling framework, missing data are accommodated simply\n",
    "by treating them as unknown model parameters. Values for the missing\n",
    "data $\\tilde{y}$ are estimated naturally, using the posterior predictive\n",
    "distribution:\n",
    "\n",
    "<div style=\"font-size: 150%;\">  \n",
    "$$p(\\tilde{y}|y) = \\int p(\\tilde{y}|\\theta) f(\\theta|y) d\\theta$$\n",
    "</div>\n",
    "\n",
    "This describes additional data $\\tilde{y}$, which may either be\n",
    "considered unobserved data or potential future observations. We can use\n",
    "the posterior predictive distribution to model the likely values of\n",
    "missing data, assuming values are missing completely at random.\n",
    "\n",
    "Consider the coal mining disasters data introduced previously. Assume\n",
    "that two years of data are missing from the time series; we indicate\n",
    "this in the data array by the use of an arbitrary placeholder value,\n",
    "`None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([ 4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n",
    "3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n",
    "2, 2, 3, 4, 2, 1, 3, None, 2, 1, 1, 1, 1, 3, 0, 0,\n",
    "1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n",
    "0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n",
    "3, 3, 1, None, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n",
    "0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate these values in PyMC, we generate a *masked array*. These are specialised NumPy arrays that contain a matching True or False value for each element to indicate if that value should be excluded from any computation. Masked arrays can be generated using NumPy's `ma.masked_equal` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_values = np.ma.masked_values(x, value=None)\n",
    "masked_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This masked array, in turn, can then be passed to one of PyMC's data\n",
    "stochastic variables, which recognizes the masked array and replaces the\n",
    "missing values with Stochastic variables of the desired type. For the\n",
    "coal mining disasters problem, recall that disaster events were modeled\n",
    "as Poisson variates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = Poisson('disasters', mu=rate, \n",
    "                    value=masked_values, observed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `rate` is an array of means for each year of data, allocated\n",
    "according to the location of the switchpoint. Each element in\n",
    "`disasters` is a Poisson Stochastic, irrespective of whether the\n",
    "observation was missing or not. The difference is that actual\n",
    "observations are data Stochastics (`observed=True`), while the missing\n",
    "values are non-data Stochastics. The latter are considered unknown,\n",
    "rather than fixed, and therefore estimated by the MCMC algorithm, just\n",
    "as unknown model parameters.\n",
    "\n",
    "The entire model looks very similar to the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_model():\n",
    "\n",
    "    # Switchpoint\n",
    "    switch = DiscreteUniform('switch', lower=0, upper=110)\n",
    "    # Early mean\n",
    "    early_mean = Exponential('early_mean', beta=1)\n",
    "    # Late mean\n",
    "    late_mean = Exponential('late_mean', beta=1)\n",
    "    \n",
    "    @deterministic(plot=False)\n",
    "    def rate(s=switch, e=early_mean, l=late_mean):\n",
    "        \"\"\"Allocate appropriate mean to time series\"\"\"\n",
    "        out = np.empty(len(disasters_array))\n",
    "        # Early mean prior to switchpoint\n",
    "        out[:s] = e\n",
    "        # Late mean following switchpoint\n",
    "        out[s:] = l\n",
    "        return out\n",
    "    \n",
    "    masked_values = np.ma.masked_values(x, value=None)\n",
    "    \n",
    "    # Pass masked array to data stochastic, and it does the right thing\n",
    "    disasters = Poisson('disasters', mu=rate, value=masked_values, observed=True)\n",
    "    \n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have used the `masked_values` function, rather than `masked_equal`; The result is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.early_mean.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_missing = MCMC(missing_data_model())\n",
    "M_missing.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matplot.plot(M_missing.disasters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the MCMC algorithm\n",
    "\n",
    "MCMC objects handle individual variables via *step methods*, which\n",
    "determine how parameters are updated at each step of the MCMC algorithm.\n",
    "By default, step methods are automatically assigned to variables by\n",
    "PyMC. To see which step methods $M$ is using, look at its\n",
    "`step_method_dict` attribute with respect to each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.step_method_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of `step_method_dict` corresponding to a particular variable\n",
    "is a list of the step methods $M$ is using to handle that variable.\n",
    "\n",
    "You can force $M$ to use a particular step method by calling `M.use_step_method` before telling it to sample. The following call will cause $M$ to handle `late_mean` with a `Slicer` (slice sampling) step method, and assigns an initial slice width `w=0.5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc import Slicer\n",
    "M.use_step_method(Slicer, disaster_model.late_mean, w=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another step method class, `AdaptiveMetropolis`, is better at handling\n",
    "highly-correlated variables. If your model mixes poorly, using\n",
    "`AdaptiveMetropolis` is a sensible first thing to try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
